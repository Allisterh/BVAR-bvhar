# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Build Response Matrix of VAR(p)
#' 
#' This function constructs response matrix of multivariate regression model formulation of VAR(p).
#' 
#' @param y Matrix, multivariate time series data.
#' @param var_lag Integer, VAR lag.
#' @param index Integer, Starting index to extract
#' 
#' @details
#' Let s = n - p.
#' \deqn{Y_j = (y_j, y_{j + 1}, \ldots, y_{j + s - 1})^T}
#' is the s x m matrix.
#' 
#' In case of response matrix, t = p + 1 (i.e. \eqn{Y_0 = Y_{p + 1}}).
#' This function is also used when constructing design matrix.
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' 
#' @export
build_y0 <- function(y, var_lag, index) {
    .Call(`_bvhar_build_y0`, y, var_lag, index)
}

#' Build Design Matrix of VAR(p)
#' 
#' This function constructs design matrix of multivariate regression model formulation of VAR(p).
#' 
#' @param y Matrix, time series data
#' @param var_lag VAR lag
#' 
#' @details
#' X0 is
#' \deqn{X_0 = [Y_p, \ldots, Y_1, 1]}
#' i.e. (n - p) x (mp + 1) matrix
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' 
#' @export
build_design <- function(y, var_lag) {
    .Call(`_bvhar_build_design`, y, var_lag)
}

#' Diagonal Matrix
#' 
#' Construct a diagonal matrix.
#' 
#' @param Vector
#' 
#' @noRd
diag_misc <- function(x) {
    .Call(`_bvhar_diag_misc`, x)
}

#' Construct Dummy response for Minnesota Prior
#' 
#' Define dummy Y observations to add for Minnesota moments.
#' 
#' @param p Integer, VAR lag. For VHAR, put 3.
#' @param sigma Vector, standard error of each variable
#' @param lambda Double, tightness of the prior around a random walk or white noise
#' @param delta Vector, prior belief about white noise (Litterman sets 1)
#' 
#' @details
#' Bańbura et al. (2010) defines dummy observation and augment to the original data matrix to construct Litterman (1986) prior.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @export
build_ydummy <- function(p, sigma, lambda, delta) {
    .Call(`_bvhar_build_ydummy`, p, sigma, lambda, delta)
}

#' Construct Dummy design matrix for Minnesota Prior
#' 
#' Define dummy X observation to add for Minnesota moments.
#' 
#' @param p Integer, VAR lag. For VHAR, put 3.
#' @param sigma Vector, standard error of each variable
#' @param lambda Double, tightness of the prior around a random walk or white noise
#' @param eps Double, very small number
#' 
#' @details
#' Bańbura et al. (2010) defines dummy observation and augment to the original data matrix to construct Litterman (1986) prior.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @export
build_xdummy <- function(p, lambda, sigma, eps) {
    .Call(`_bvhar_build_xdummy`, p, lambda, sigma, eps)
}

#' Parameters of Normal Inverted Wishart Prior
#' 
#' Given dummy observations, compute parameters of Normal-IW prior for Minnesota.
#' 
#' @param x_dummy Matrix, dummy observation for X0
#' @param y_dummy Matrix, dummy observation for Y0
#' 
#' @details
#' Minnesota prior give prior to parameters \eqn{B} (VAR matrices) and \eqn{\Sigma_e} (residual covariance) the following distributions
#' 
#' \deqn{B \mid \Sigma_e, Y_0 \sim MN(B_0, \Omega_0, \Sigma_e)}
#' \deqn{\Sigma_e \mid Y_0 \sim IW(S_0, \alpha_0)}
#' (MN: [matrix normal](https://en.wikipedia.org/wiki/Matrix_normal_distribution), IW: [inverse-wishart](https://en.wikipedia.org/wiki/Inverse-Wishart_distribution))
#' 
#' Bańbura et al. (2010) provides the formula how to find each matrix to match Minnesota moments.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @export
minnesota_prior <- function(x_dummy, y_dummy) {
    .Call(`_bvhar_minnesota_prior`, x_dummy, y_dummy)
}

#' Construct Dummy response for Second Version of BVHAR Minnesota Prior
#' 
#' Define dummy Y observations to add for Minnesota moments.
#' This function also fills zero matrix in the first block for applying to VHAR.
#' 
#' @param sigma Vector, standard error of each variable
#' @param lambda Double, tightness of the prior around a random walk or white noise
#' @param daily Vector, instead of delta vector in the original Minnesota design (Litterman sets 1).
#' @param weekly Vector, this was zero in the original Minnesota design
#' @param monthly Vector, this was zero in the original Minnesota design
#' 
#' @details
#' Bańbura et al. (2010) defines dummy observation and augment to the original data matrix to construct Litterman (1986) prior.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @export
build_ydummy_bvhar <- function(sigma, lambda, daily, weekly, monthly) {
    .Call(`_bvhar_build_ydummy_bvhar`, sigma, lambda, daily, weekly, monthly)
}

#' BVAR(p) Point Estimates based on Minnesota Prior
#' 
#' Point estimates for posterior distribution
#' 
#' @param x Matrix, X0
#' @param y Matrix, Y0
#' @param x_dummy Matrix, dummy X0
#' @param y_dummy Matrix, dummy Y0
#' 
#' @details
#' Augment originally processed data and dummy observation.
#' OLS from this set gives the result.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @export
estimate_bvar_mn <- function(x, y, x_dummy, y_dummy) {
    .Call(`_bvhar_estimate_bvar_mn`, x, y, x_dummy, y_dummy)
}

#' BVAR(p) Point Estimates based on Nonhierarchical Matrix Normal Prior
#' 
#' Point estimates for Ghosh et al. (2018) nonhierarchical model for BVAR.
#' 
#' @param x Matrix, X0
#' @param y Matrix, Y0
#' @param U Positive definite matrix, covariance matrix corresponding to the column of the model parameter B
#' 
#' @details
#' In Ghosh et al. (2018), there are many models for BVAR such as hierarchical or non-hierarchical.
#' Among these, this function chooses the most simple non-hierarchical matrix normal prior in Section 3.1.
#' 
#' @references
#' Ghosh, S., Khare, K., & Michailidis, G. (2018). \emph{High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models}. Journal of the American Statistical Association, 114(526). \url{https://doi:10.1080/01621459.2018.1437043}
#' 
#' @export
estimate_mn_flat <- function(x, y, U) {
    .Call(`_bvhar_estimate_mn_flat`, x, y, U)
}

#' Compute VAR(p) Coefficient Matrices and Fitted Values
#' 
#' This function fits VAR(p) given response and design matrices of multivariate time series.
#' 
#' @param x X0 processed by [build_design()]
#' @param y Y0 processed by [build_y0()]
#' @details
#' Given Y0 and Y0, the function estimate least squares
#' Y0 = X0 A + Z
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
estimate_var <- function(x, y) {
    .Call(`_bvhar_estimate_var`, x, y)
}

#' Covariance Estimate for Residual Covariance Matrix
#' 
#' Compute ubiased estimator for residual covariance.
#' 
#' @param z Matrix, residual
#' @param num_design Integer, Number of sample used (s = n - p)
#' @param dim_design Ingeger, Number of parameter for each dimension (k = mp + 1)
#' @details
#' See pp75 Lütkepohl (2007).
#' 
#' * s = n - p: sample used (`num_design`)
#' * k = mp + 1 (m: dimension, p: VAR lag): number of parameter for each dimension (`dim_design`)
#' 
#' Then an unbiased estimator for \eqn{\Sigma_e} is
#' 
#' \deqn{\hat{\Sigma}_e = \frac{1}{s - k} (Y_0 - \hat{A} X_0)^T (Y_0 - \hat{A} X_0)}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
compute_cov <- function(z, num_design, dim_design) {
    .Call(`_bvhar_compute_cov`, z, num_design, dim_design)
}

#' @noRd
VARcoeftoVMA <- function(var_coef, var_lag, lag_max) {
    .Call(`_bvhar_VARcoeftoVMA`, var_coef, var_lag, lag_max)
}

#' Convert VAR to VMA(infinite)
#' 
#' Convert VAR process to infinite vector MA process
#' 
#' @param object `varlse` object
#' @param lag_max Maximum lag for VMA
#' @details
#' Let VAR(p) be stable.
#' \deqn{Y_t = c + \sum_{j = 0} W_j Z_{t - j}}
#' For VAR coefficient \eqn{B_1, B_2, \ldots, B_p},
#' \deqn{I = (W_0 + W_1 L + W_2 L^2 + \cdots + ) (I - B_1 L - B_2 L^2 - \cdots - B_p L^p)}
#' Recursively,
#' \deqn{W_0 = I}
#' \deqn{W_1 = W_0 B_1 (W_1^T = B_1^T W_0^T)}
#' \deqn{W_2 = W_1 B_1 + W_0 B_2 (W_2^T = B_1^T W_1^T + B_2^T W_0^T)}
#' \deqn{W_j = \sum_{j = 1}^k W_{k - j} B_j (W_j^T = \sum_{j = 1}^k B_j^T W_{k - j}^T)}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
VARtoVMA <- function(object, lag_max) {
    .Call(`_bvhar_VARtoVMA`, object, lag_max)
}

#' Compute Forecast MSE Matrices
#' 
#' Compute the forecast MSE matrices using VMA coefficients
#' 
#' @param object `varlse` object
#' @param step Integer, Step to forecast
#' @details
#' See pp38 of Lütkepohl (2007).
#' Let \eqn{\Sigma} be the covariance matrix of VAR and let \eqn{W_j} be the VMA coefficients.
#' Recursively,
#' \deqn{\Sigma_y(1) = \Sigma}
#' \deqn{\Sigma_y(2) = \Sigma + W_1 \Sigma W_1^T}
#' \deqn{\Sigma_y(3) = \Sigma_y(2) + W_2 \Sigma W_2^T}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
compute_covmse <- function(object, step) {
    .Call(`_bvhar_compute_covmse`, object, step)
}

#' Building a Linear Transformation Matrix for Vector HAR
#' 
#' This function produces a linear transformation matrix for VHAR for given dimension.
#' 
#' @param m integer, dimension
#' @details
#' VHAR is linearly restricted VAR(22) in \eqn{Y_0 = X_0 A + Z}.
#' 
#' \deqn{Y_0 = X_1 \Phi + Z = (X_0 T_{HAR}^T) \Phi + Z}
#' 
#' This function computes above \eqn{T_{HAR}}.
#' 
#' @export
scale_har <- function(m) {
    .Call(`_bvhar_scale_har`, m)
}

#' Compute Vector HAR Coefficient Matrices and Fitted Values
#' 
#' This function fits VHAR given response and design matrices of multivariate time series.
#' 
#' @param x X0 processed by \code{\link{build_design}}
#' @param y Y0 processed by \code{\link{build_y0}}
#' @details
#' Given Y0 and Y0, the function estimate least squares
#' \deqn{Y_0 = X_1 \Phi + Z}
#' 
#' @references
#' Lütkepohl, H. (2007). \emph{New Introduction to Multiple Time Series Analysis}. Springer Publishing. \url{https://doi.org/10.1007/978-3-540-27752-1}
#' 
#' Corsi, F. (2008). \emph{A Simple Approximate Long-Memory Model of Realized Volatility}. Journal of Financial Econometrics, 7(2), 174–196. \url{https://doi:10.1093/jjfinec/nbp001}
#' 
#' @importFrom Rcpp sourceCpp
#' @export
estimate_har <- function(x, y) {
    .Call(`_bvhar_estimate_har`, x, y)
}

#' Compute Vector HAR Coefficient Matrices and Fitted Values without Constant Term
#' 
#' This function fits VHAR given response and design matrices of multivariate time series, when the model has no constant term.
#' 
#' @param x X0 processed by \code{\link{build_design}} (delete its last column)
#' @param y Y0 processed by \code{\link{build_y0}}
#' @details
#' Given Y0 and Y0, the function estimate least squares
#' \deqn{Y_0 = X_1 \Phi + Z}
#' 
#' @references
#' Lütkepohl, H. (2007). \emph{New Introduction to Multiple Time Series Analysis}. Springer Publishing. \url{https://doi.org/10.1007/978-3-540-27752-1}
#' 
#' Corsi, F. (2008). \emph{A Simple Approximate Long-Memory Model of Realized Volatility}. Journal of Financial Econometrics, 7(2), 174–196. \url{https://doi:10.1093/jjfinec/nbp001}
#' 
#' @export
estimate_har_none <- function(x, y) {
    .Call(`_bvhar_estimate_har_none`, x, y)
}

#' @noRd
VHARcoeftoVMA <- function(vhar_coef, HARtrans_mat, lag_max) {
    .Call(`_bvhar_VHARcoeftoVMA`, vhar_coef, HARtrans_mat, lag_max)
}

#' Convert VHAR to VMA(infinite)
#' 
#' Convert VHAR process to infinite vector MA process
#' 
#' @param object \code{vharlse} object by \code{\link{vhar_lm}}
#' @param lag_max Maximum lag for VMA
#' @details
#' Let VAR(p) be stable
#' and let VAR(p) be
#' \eqn{Y_0 = X_0 B + Z}
#' 
#' VHAR is VAR(22) with
#' \deqn{Y_0 = X_1 B + Z = ((X_0 \tilde{T}^T)) \Phi + Z}
#' 
#' Observe that
#' \deqn{B = \tilde{T}^T \Phi}
#' 
#' @references Lütkepohl, H. (2007). \emph{New Introduction to Multiple Time Series Analysis}. Springer Publishing. \url{https://doi.org/10.1007/978-3-540-27752-1}
#' @export
VHARtoVMA <- function(object, lag_max) {
    .Call(`_bvhar_VHARtoVMA`, object, lag_max)
}

#' Compute Forecast MSE Matrices for VHAR
#' 
#' Compute the forecast MSE matrices using VMA coefficients
#' 
#' @param object \code{varlse} object by \code{\link{var_lm}}
#' @param step Integer, Step to forecast
#' @details
#' See pp38 of Lütkepohl (2007).
#' Let \eqn{\Sigma} be the covariance matrix of VHAR and let \eqn{W_j} be the VMA coefficients.
#' Recursively,
#' \deqn{\Sigma_y(1) = \Sigma}
#' \deqn{\Sigma_y(2) = \Sigma + W_1 \Sigma W_1^T}
#' \deqn{\Sigma_y(3) = \Sigma_y(2) + W_2 \Sigma W_2^T}
#' 
#' @references Lütkepohl, H. (2007). \emph{New Introduction to Multiple Time Series Analysis}. Springer Publishing. \url{https://doi.org/10.1007/978-3-540-27752-1}
#' @export
compute_covmse_har <- function(object, step) {
    .Call(`_bvhar_compute_covmse_har`, object, step)
}

#' Forecasting BVAR(p)
#' 
#' @param object `bvarmn` or `bvarflat` object
#' @param step Integer, Step to forecast
#' @param num_sim Integer, number to simulate parameters from posterior distribution
#' @details
#' n-step ahead forecasting using BVAR(p) recursively.
#' 
#' For given number of simulation (`num_sim`),
#' 
#' 1. Generate \eqn{(A^{(b)}, \Sigma_e^{(b)}) \sim MIW} (posterior)
#' 2. Recursively, \eqn{j = 1, \ldots, h} (`step`)
#'     - Point forecast: Use \eqn{\hat{A}}
#'     - Predictive distribution: Again generate \eqn{\tilde{Y}_{n + j}^{(b)} \sim A^{(b)}, \Sigma_e^{(b)} \sim MN}
#'     - tilde notation indicates simulated ones
#' 
#' @references
#' Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' 
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' Ghosh, S., Khare, K., & Michailidis, G. (2018). *High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models*. Journal of the American Statistical Association, 114(526). [https://doi:10.1080/01621459.2018.1437043](https://doi:10.1080/01621459.2018.1437043)
#' 
#' Karlsson, S. (2013). *Chapter 15 Forecasting with Bayesian Vector Autoregression*. Handbook of Economic Forecasting, 2, 791–897. doi:[10.1016/b978-0-444-62731-5.00015-4](https://doi.org/10.1016/B978-0-444-62731-5.00015-4)
#' 
#' @export
forecast_bvar <- function(object, step, num_sim) {
    .Call(`_bvhar_forecast_bvar`, object, step, num_sim)
}

#' Forecasting Bayesian VHAR
#' 
#' @param object `bvharmn` object
#' @param step Integer, Step to forecast
#' @param num_sim Integer, number to simulate parameters from posterior distribution
#' @details
#' n-step ahead forecasting using VHAR recursively.
#' 
#' For given number of simulation (`num_sim`),
#' 
#' 1. Generate \eqn{(\Phi^{(b)}, \Sigma_e^{(b)}) \sim MIW} (posterior)
#' 2. Recursively, \eqn{j = 1, \ldots, h} (`step`)
#'     - Point forecast: Use \eqn{\hat\Phi}
#'     - Predictive distribution: Again generate \eqn{\tilde{Y}_{n + j}^{(b)} \sim \Phi^{(b)}, \Sigma_e^{(b)} \sim MN}
#'     - tilde notation indicates simulated ones
#' 
#' @references
#' Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' 
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' Karlsson, S. (2013). *Chapter 15 Forecasting with Bayesian Vector Autoregression*. Handbook of Economic Forecasting, 2, 791–897. doi:[10.1016/b978-0-444-62731-5.00015-4](https://doi.org/10.1016/B978-0-444-62731-5.00015-4)
#' 
#' @export
forecast_bvharmn <- function(object, step, num_sim) {
    .Call(`_bvhar_forecast_bvharmn`, object, step, num_sim)
}

#' Forecasting Vector Autoregression
#' 
#' @param object \code{varlse} object by \code{\link{var_lm}}
#' @param step Integer, Step to forecast
#' @details
#' n-step ahead forecasting using VAR(p) recursively, based on pp35 of Lütkepohl (2007).
#' 
#' @references Lütkepohl, H. (2007). \emph{New Introduction to Multiple Time Series Analysis}. Springer Publishing. \url{https://doi.org/10.1007/978-3-540-27752-1}
#' @export
forecast_var <- function(object, step) {
    .Call(`_bvhar_forecast_var`, object, step)
}

#' Forecasting Vector HAR
#' 
#' @param object \code{varlse} object by \code{\link{vhar_lm}}
#' @param step Integer, Step to forecast
#' @details
#' n-step ahead forecasting using VHAR recursively.
#' 
#' @export
forecast_vhar <- function(object, step) {
    .Call(`_bvhar_forecast_vhar`, object, step)
}

#' Generate Multivariate Normal Random Vector with Zero Mean
#' 
#' This function samples n x muti-dimensional normal random matrix with zero mean vector.
#' 
#' @param num_sim Number to generate process
#' @param mu Mean vector
#' @param sig Variance matrix
#' @details
#' Consider \eqn{x_1, \ldots, x_n \sim N_m (\mu, \Sigma)}.
#' 
#' 1. Lower triangular Cholesky decomposition: \eqn{\Sigma = L L^T}
#' 2. Standard normal generation: \eqn{Z_{i1}, Z_{in} \stackrel{iid}{\sim} N(0, 1)}
#' 3. \eqn{Z_i = (Z_{i1}, \ldots, Z_{in})^T}
#' 4. \eqn{X_i = L Z_i + \mu}
#' 
#' This function does not care of \eqn{\mu}.
#' 
#' @export
sim_mgaussian <- function(num_sim, mu, sig) {
    .Call(`_bvhar_sim_mgaussian`, num_sim, mu, sig)
}

#' Generate Matrix Normal Random Matrix
#' 
#' This function samples one matrix gaussian matrix.
#' 
#' @param mat_mean Mean matrix
#' @param mat_scale_u First scale matrix
#' @param mat_scale_v Second scale matrix
#' @details
#' Consider s x m matrix \eqn{Y_1, \ldots, Y_n \sim MN(M, U, V)} where M is s x m, U is s x s, and V is m x m.
#' 
#' 1. Lower triangular Cholesky decomposition: \eqn{U = P P^T} and \eqn{V = L L^T}
#' 2. Standard normal generation: s x m matrix \eqn{Z_i = [z_{ij} \sim N(0, 1)]} in row-wise direction.
#' 3. \eqn{Y_i = M + P Z_i L^T}
#' 
#' This function only generates one matrix, i.e. \eqn{Y_1}.
#' 
#' @export
sim_matgaussian <- function(mat_mean, mat_scale_u, mat_scale_v) {
    .Call(`_bvhar_sim_matgaussian`, mat_mean, mat_scale_u, mat_scale_v)
}

#' Generate Lower Triangular Matrix of IW
#' 
#' This function generates \eqn{A = L (Q^{-1})^T}.
#' 
#' @param mat_scale Scale matrix of IW
#' @param shape Shape of IW
#' @details
#' This function is the internal function for IW sampling and MNIW sampling functions.
#' 
#' @noRd
sim_iw_tri <- function(mat_scale, shape) {
    .Call(`_bvhar_sim_iw_tri`, mat_scale, shape)
}

#' Generate Inverse-Wishart Random Matrix
#' 
#' This function samples one matrix IW matrix.
#' 
#' @param mat_scale Scale matrix
#' @param shape Shape
#' @details
#' Consider \eqn{\Sigma \sim IW(\Psi, \nu)}.
#' 
#' 1. Upper triangular Bartlett decomposition: m x m matrix \eqn{Q = [q_{ij}]} upper triangular with
#'     1. \eqn{q_{ii}^2 \chi_{\nu - i + 1}^2}
#'     2. \eqn{q_{ij} \sim N(0, 1)} with i < j (upper triangular)
#' 2. Lower triangular Cholesky decomposition: \eqn{\Psi = L L^T}
#' 3. \eqn{A = L (Q^{-1})^T}
#' 4. \eqn{\Sigma = A A^T \sim IW(\Psi, \nu)}
#' 
#' @export
sim_iw <- function(mat_scale, shape) {
    .Call(`_bvhar_sim_iw`, mat_scale, shape)
}

#' Generate Normal-IW Random Family
#' 
#' This function samples normal inverse-wishart matrices.
#' 
#' @param num_sim Number to generate
#' @param mat_mean Mean matrix of MN
#' @param mat_scale_u First scale matrix of MN
#' @param mat_scale Scale matrix of IW
#' @param shape Shape of IW
#' @details
#' Consider \eqn{(Y_i, \Sigma_i) \sim MIW(M, U, \Psi, \nu)}.
#' 
#' 1. Generate upper triangular factor of \eqn{\Sigma_i = C_i C_i^T} in the upper triangular Bartlett decomposition.
#' 2. Standard normal generation: s x m matrix \eqn{Z_i = [z_{ij} \sim N(0, 1)]} in row-wise direction.
#' 3. Lower triangular Cholesky decomposition: \eqn{U = P P^T}
#' 4. \eqn{A_i = M + P Z_i C_i^T}
#' 
#' @export
sim_mniw <- function(num_sim, mat_mean, mat_scale_u, mat_scale, shape) {
    .Call(`_bvhar_sim_mniw`, num_sim, mat_mean, mat_scale_u, mat_scale, shape)
}

#' VAR(1) Representation of VAR(p)
#' 
#' Compute the coefficient matrix of VAR(1) form
#' 
#' @param object Model fit
#' @details
#' Each VAR(p) process can be represented by mp-dim VAR(1).
#' 
#' \deqn{Y_t = B Y_{t - 1} + C + U_t}
#' 
#' where
#' 
#' \deqn{
#'     B = \begin{bmatrix}
#'       B_1 & B_2 & \cdots B_{p - 1} & B_p \        \
#'       I_m & 0 & \cdots & 0 & 0 \                  \
#'       0 & I_m & \cdots & 0 & 0 \                  \
#'       \vdots & \vdots & \vdots & \vdots & \vdots \\
#'       0 & 0 & \cdots & I_m & 0
#'     \end{bmatrix}
#' }
#' 
#' \deqn{C = (c, 0, \ldots, 0)^T}
#' 
#' and
#' 
#' \deqn{U_t = (\epsilon_t, 0, \ldots, 0)^T}
#' 
#' @references Lütkepohl, H. (2007). \emph{New Introduction to Multiple Time Series Analysis}. Springer Publishing. \url{https://doi.org/10.1007/978-3-540-27752-1}
#' @export
compute_stablemat <- function(object) {
    .Call(`_bvhar_compute_stablemat`, object)
}

#' @noRd
kronecker_eigen <- function(x, y) {
    .Call(`_bvhar_kronecker_eigen`, x, y)
}

#' @noRd
compute_eigenvalues <- function(x) {
    .Call(`_bvhar_compute_eigenvalues`, x)
}

#' Multivariate Gamma Function
#' 
#' Compute multivariate gamma function numerically
#' 
#' @param x Double, non-negative argument
#' @param p Integer, dimension
#' 
#' @noRd
mgammafn <- function(x, p) {
    .Call(`_bvhar_mgammafn`, x, p)
}

#' Log of Multivariate Gamma Function
#' 
#' Compute log of multivariate gamma function numerically
#' 
#' @param x Double, non-negative argument
#' @param p Integer, dimension
#' 
#' @noRd
log_mgammafn <- function(x, p) {
    .Call(`_bvhar_log_mgammafn`, x, p)
}

#' Generate Multivariate Time Series Process Following VAR(p)
#' 
#' This function generates multivariate time series dataset that follows VAR(p).
#' 
#' @param num_sim Number to generated process
#' @param num_burn Number of burn-in
#' @param var_coef VAR coefficient. The format should be the same as the output of [var_lm()]
#' @param var_lag Lag of VAR
#' @param sig_error Variance matrix of the error term. Try `diag(dim)`.
#' @param init Initial y1, ..., yp matrix to simulate VAR model. Try `matrix(0L, nrow = var_lag, ncol = dim)`.
#' @details
#' 1. Generate \eqn{\epsilon_1, \epsilon_n \sim N(0, \Sigma)}
#' 2. For i = 1, ... n,
#' \deqn{y_{p + i} = (y_{p + i - 1}^T, \ldots, y_i^T, 1)^T B + \epsilon_i}
#' 3. Then the output is \eqn{(y_{p + 1}, \ldots, y_{n + p})^T}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
sim_var <- function(num_sim, num_burn, var_coef, var_lag, sig_error, init) {
    .Call(`_bvhar_sim_var`, num_sim, num_burn, var_coef, var_lag, sig_error, init)
}

#' Generate Multivariate Time Series Process Following VHAR
#' 
#' This function generates multivariate time series dataset that follows VHAR.
#' 
#' @param num_sim Number to generated process
#' @param num_burn Number of burn-in
#' @param vhar_coef VHAR coefficient. The format should be the same as the output of [vhar_lm()]
#' @param sig_error Variance matrix of the error term. Try `diag(dim)`.
#' @param init Initial y1, ..., yp matrix to simulate VAR model. Try `matrix(0L, nrow = 22L, ncol = dim)`.
#' @details
#' 1. Generate \eqn{\epsilon_1, \epsilon_n \sim N(0, \Sigma)}
#' 2. For i = 1, ... n,
#' \deqn{y_{22 + i} = (y_{21 + i}^T, \ldots, y_i^T, 1)^T T_{HAR}^T \Phi + \epsilon_i}
#' 3. Then the output is \eqn{(y_{23}, \ldots, y_{n + 22})^T}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
sim_vhar <- function(num_sim, num_burn, vhar_coef, sig_error, init) {
    .Call(`_bvhar_sim_vhar`, num_sim, num_burn, vhar_coef, sig_error, init)
}

#' Numerically Stable Log Marginal Likelihood Excluding Constant Term
#' 
#' This function computes log of ML stable,
#' in purpose of objective function.
#' 
#' @param object Bayesian Model Fit
#' 
#' @noRd
logml_stable <- function(object) {
    .Call(`_bvhar_logml_stable`, object)
}

#' AIC of VAR(p) using RSS
#' 
#' Compute AIC using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_aic <- function(object) {
    .Call(`_bvhar_compute_aic`, object)
}

#' BIC of VAR(p) using RSS
#' 
#' Compute BIC using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_bic <- function(object) {
    .Call(`_bvhar_compute_bic`, object)
}

#' HQ of VAR(p) using RSS
#' 
#' Compute HQ using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_hq <- function(object) {
    .Call(`_bvhar_compute_hq`, object)
}

#' FPE of VAR(p) using RSS
#' 
#' Compute FPE using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_fpe <- function(object) {
    .Call(`_bvhar_compute_fpe`, object)
}

#' Choose the Best VAR based on Information Criteria
#' 
#' This function computes AIC, FPE, BIC, and HQ up to p = `lag_max` of VAR model.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag_max Maximum Var lag to explore
#' @param include_mean Add constant term
#' 
#' @noRd
tune_var <- function(y, lag_max, include_mean) {
    .Call(`_bvhar_tune_var`, y, lag_max, include_mean)
}

