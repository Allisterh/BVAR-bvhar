% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bvar-ghosh.R, R/print-bvarghosh.R
\name{bvar_flat}
\alias{bvar_flat}
\alias{print.bvarflat}
\alias{knit_print.bvarflat}
\title{Fit Bayesian VAR(p) of Nonhiearchical Matrix Normal Prior}
\usage{
bvar_flat(y, p, U, type = c("const", "none"))

\method{print}{bvarflat}(x, digits = max(3L, getOption("digits") - 3L), ...)

knit_print.bvarflat(x, ...)
}
\arguments{
\item{y}{Time series data of which columns indicate the variables}

\item{p}{VAR lag}

\item{U}{Positive definite matrix. By default, identity matrix of dimension ncol(X0)}

\item{type}{\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}} add constant term (\code{"const"}) or not (\code{"none"})}

\item{x}{\code{bvarflat} object}

\item{digits}{digit option to print}

\item{...}{not used}
}
\value{
\code{bvar_flat} returns an object \code{bvarflat} \link{class}.
It is a list with the following components:

\describe{
\item{design}{\eqn{X_0}}
\item{y0}{\eqn{Y_0}}
\item{y}{Raw input}
\item{p}{Lag of VAR}
\item{m}{Dimension of the data}
\item{obs}{Sample size used when training = \code{totobs} - \code{p}}
\item{totobs}{Total number of the observation}
\item{process}{Process: Ghosh}
\item{call}{Matched call}
\item{mn_mean}{Location of posterior matrix normal distribution}
\item{fitted.values}{Fitted values}
\item{residuals}{Residuals}
\item{mn_prec}{Precision matrix of posterior matrix normal distribution}
\item{iw_scale}{Scale matrix of posterior inverse-wishart distribution}
\item{iw_shape}{Shape of posterior inverse-wishart distribution}
}
}
\description{
This function fits BVAR(p) with Ghosh et al. (2018) nonhierarchical prior.
}
\details{
Ghosh et al. (2018) gives flat prior for residual matrix in BVAR.

Under this setting, there are many models such as hierarchical or non-hierarchical.
This function chooses the most simple non-hierarchical matrix normal prior in Section 3.1.

\deqn{B \mid \Sigma_e \sim MN(0, U^{-1}, \Sigma_e)}
\eqn{\Sigma_e \sim} flat
where U: precision matrix.

Then in VAR design equation (Y0 = X0 B + Z),
MN mean can be derived by
\deqn{\hat{B} = (X_0^T X_0 + U)^{-1} X_0^T Y_0}
and the MN scale matrix can be derived by
\deqn{\hat\Sigma_e = Y_0^T (I_s - X_0(X_0^T X_0 + U)^{-1} X_0^T) Y_0}
and IW shape by \eqn{s - m - 1}.

(MN: \href{https://en.wikipedia.org/wiki/Matrix_normal_distribution}{matrix normal}, IW: \href{https://en.wikipedia.org/wiki/Inverse-Wishart_distribution}{inverse-wishart}).
}
\references{
Litterman, R. B. (1986). \emph{Forecasting with Bayesian Vector Autoregressions: Five Years of Experience}. Journal of Business & Economic Statistics, 4(1), 25. \url{https://doi:10.2307/1391384}

Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). \emph{Large Bayesian vector auto regressions}. Journal of Applied Econometrics, 25(1). \url{https://doi:10.1002/jae.1137}

Ghosh, S., Khare, K., & Michailidis, G. (2018). \emph{High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models}. Journal of the American Statistical Association, 114(526). \url{https://doi:10.1080/01621459.2018.1437043}
}
